---
title: "Neural network from scratch"
excerpt: "Implementation of a neural network without libraries."
collection: portfolio
---

[I built a 3 layer neural network from scratch](https://github.com/seckinkurklu/neural-network-from-scratch) using only NumPy (and a little Pandas). I implemented ReLU activation for the hidden layer and softmax for the output layer. The model was trained on the MNIST handwritten digit dataset using gradient descent and backpropagation, with training accuracy steadily improving from random chance to approximately 85% over 500 iterations. This project demonstrates a full implementation of neural network training without relying on any ML libraries.